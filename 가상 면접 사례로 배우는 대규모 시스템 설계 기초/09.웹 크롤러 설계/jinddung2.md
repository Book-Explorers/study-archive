## 다루는 내용

- 검색 엔진 인덱싱
- 웹 아카이빙
- 웹 마이닝
- 웹 모니터링

## 1단계) 문제 이해 및 설계 범위 확정

- 규모확장성: 병행성을 활용하면 보다 효과적으로 웹 크롤링 가능하다.
- 안정성: 잘못 작성된 HTML, 아무 반응 없는 서버, 장애, 악성 코드가 붙어 있는 링크 등의 함정으로 가득한 웹으로부터 잘 대응해야 한다.
- 예절: 크롤러는 수집 대상 웹사이트에 짧은 시간 동안 너무 많은 요청을 보내면 안 된다.
- 확장성: 새로운 형태의 콘텐츠를 지원하기 쉬워야 한다.

## 2단계) 개략적 설계안 제시 및 동의 구하

### 시작 URL 집합

- 웹 크롤러가 크롤링을 시작하는 출발점이다.
- 모든 웹 페이지를 크롤링하는 가장 직관적인 방법은 해당 대학의 도메인 이름이 붙은 모든 페이지의 URL을 시작 URL로 쓰는 것이다.
- 일반적으로는 전체 URL 공간을 작은 부분집합으로 나누는 전략을 쓴다.
- 주제별로 다른 시작 URL을 사용하는 것이다.

### 미수집 URL 저장소

- 웹 크롤러는 크롤링 상태를 다운로드할 URL, 그리고 다운로드 된 URL의 두 가지로 나눠 관리한다.
- 다운로드 할 URL을 저장 관리하는 컴포넌트를 미수집 URL라고 부른다.(FIFO 큐)

### HTML 다운로더

- 인터넷에서 웹 페이지를 다운로드하는 컴포넌트다.
- 미수집 URL 저장소가 제공한다.

### 도메인 이름 변환기

- HTML 다운로더는 도메인 이름 변환기를 사용하여 URL에 대응되는 IP 주소를 알아낸다.

### **콘텐츠 파서**

- 웹 페이지를 다운로드하면 파싱과 검증 절차를 거쳐야 한다.
- 크롤링 서버 안에 파서를 구현하면 크롤링 과정이 느려지게 되니 독립된 컴포넌트로 만든다.

### **중복 콘텐츠인가?**

- 효과적인 방법은 웹 페이지의 해시 값을 비교하는 것이다.

### **콘텐츠 저장소**

- 콘텐츠 저장소는 HTML 문서를 보관하는 시스템이다.
- 저장소를 구현하는 데 쓰일 기술을 고를 때는 저장할 데이터 유형, 크기, 저장소 접근 빈도, 데이터 유효 기간 등을 종합적으로 고려해야 한다.

### **URL 추출기**

- URL 추출기는 HTML 페이지를 파싱하여 링크들을 골라내는 역할을 한다.

### **URL 필터**

- URL 필터는 특정한 콘텐츠 타입이나 파일 확장자를 갖는 URL, 접속 시 오류가 발생하는 URL, 접근 제외 목록 등 크롤링 대상에서 배제하는 역할을 한다.

### **이미 방문한 URL?**

- 이미 방문한 적이 있는 URL인지 추적하면 같은 URL을 여러 번 처리하는 일을 방지할 수 있으므로 서버 부하를 줄이고, 시스템이 무한 루프에 빠지는 일을 방지할 수 있다.
- 블 필터나 해시 테이블

### **URL 저장소**

- URL 저장소는 이미 방문한 URL을 보관하는 저장소다.

웹 크롤러 작업 흐름: p.149

## 3단계) 상세 설계

### DFS vs BFS

- DFS는 좋은 선택이 아닐 가능성이 높다. 그래프 크기가 클 경우 어느 깊이까지 가게 될지 가늠이 힘들기 때문이다.
- 보통 BFS를 활용하여, 큐에 탐색할 URL을 넣는다.
    - 동일한 서버의 다른 페이지를 참조하는데, 병렬로 처리하면 서버는 수많은 요청에 과부하가 걸린다. → 예의 없는 크롤러로 간주된다.
    - 일반적인 BFS는 우선순위가 없다. 하지만 모든 웹 페이지가 같은 수준의 품질, 중요성을 갖지 않으니 페이지 순위, 사용자 트래픽의 양, 업데이트 빈도 등 여러 가지 척도에 비추어 우선순위를 구별하는 것이 온당하다.

### 미수집 URL 저장소

- **예의:** 웹 크롤러는 수집 대상 서버로 짧은 시간 안에 너무 많은 요청을 보내는 것을 삼가야 한다. 동일 웹 사이트에 대해서는 한 번에 한 페이지만 요청해야 한다.
    - 큐 라우터
    - 매핑 테이블
    - FIFO 큐
    - 큐 선택기
    - 작업 스레드
- **우선순위:** 페이지랭크, 트래픽 양, 갱신 빈도 등 다양한 척도를 사용하여 우선순위를 정할 수 있다.
    - 순위결정장치
    - 큐
    - 큐 선택기
    - 전면 큐
    - 후면 큐
- **신선도:** 데이터의 신선함을 유지하기 위해서는 이미 다운로드한 페이지라고 해도 주기적으로 재수집할 필요가 있다.
    - 웹 페이지의 변경 이력 활
    - 우선순위를 활용하여, 중요한 페이지는 좀 더 자주 재수집
- **미수집 URL 저장소를 위한 지속성 저장장치:** 대부분의 URL은 디스크에 두지만 IO 비용을 줄이기 위해 메모리 버퍼에 큐를 두는 것이다.

### HTML 다운로더

- HTTP 프로토콜을 통해 웹 페이지를 내려 받는다.
- **Robots.txt:** 웹사이트가 크롤러와 소통하는 표준적 방법이다.

  > https://naver.com/robots.txt
  >
  >
  > User-agent: *
  > Disallow: /
  > Allow : /$
  >
  > https://ko.wikipedia.org/robots.txt
>
- **성능 최적화**
    - 분산 크롤링: 크롤링 작업을 여러 서버에 분산하는 방법이다.
    - 도메인 이름 변환 결과 캐시: 도메인 이름 변환기는 크롤러 성능 병목 중 하나인데, 동기적 특성 때문이다. DNS 조회 결과로 얻어진 도메인 이름과 IP 주소 사이의 관계를 캐시에 보관해두고 크론 잡을 돌려 주기적으로 갱신하도록 한다.
    - 지역성: 수행하는 서버를 지역별로 분산하는 방법이다.
    - 짧은 타임아웃: 대기 시간이 길어지면 좋지 않으므로, 최대 얼마나 기다릴지를 미리 정해두는 것이다.
- **안정성**
    - 안정 해시
    - 크롤링 상태 및 수집 데이터 저장
    - 예외 처리
    - 데이터 검증
- **확장성**
- **문제 있는 콘텐츠 감지 및 회피**
    - 중복 컨텐츠: 해시나 체크섬을 사용하면 쉽게 탐지할 수 있다.
    - 거미 덫: 크롤러를 무한 루프에 빠뜨리도록 설계한 웹페이지
    - 데이터 노이즈: 가치 없는 콘텐츠

## 4단계) 마무리

- 서버측 렌더링
- 원치 않는 페이지 필터링
- 데이터베이스 다중화 및 샤딩
- 수평적 규모 확장성
- 가용성, 일관성, 안정성
- 데이터 분석 솔루션
