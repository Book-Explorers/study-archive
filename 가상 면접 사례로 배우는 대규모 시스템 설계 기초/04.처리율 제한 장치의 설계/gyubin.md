# 4. 처리율 제한 장치의 설계

## 처리율 제한 장치 - Rate Limit(Throttling이라고도 함)
클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate)을 제어하기 위한 장치.
API 요청 횟수가 제한 장치에 정의된 임계치(threshold)를 넘어서면 추가로 들어온 요청의 처리는 block 된다.처리율 제한 장치는 얼마나 많은 요청이 접수되었는지를 추적할 수 있는 카운터를 추적 대상별(사용자별, IP 별, API 엔드포인트 별)로 두고 이 카운터 값이 어떤 한도를 넘어서면 그 이후에 도착한 요청은 거부하는 것이다.

처리율 제한 장치를 두면 좋은 점은 아래와 같다.
- Dos(Denial of Service) 공격에 의한 자원 고갈을 방지할 수 있다.
- 비용절감을 할 수 있다. 외부 API에 사용료를 지불하고 있는 회사들에게 아주 중요한 부분이다.
- 서버의 과부하를 막을 수 있다.
## 1단계: 문제 이해 및 설계 범위 확정
1. 클라이언트, 서버 중 어느 곳에 처리율 제한 장치를 설계할지 가정한다.
2. API 호출을 제한할 규칙을 정의한다.
3. 여러 가지 환경(단일, 분산, 대규모 트래픽 등)을 고려하여 처리율 제한 장치를 애플리케이션 코드에 포함할지 독립적인 서비스로 설계할지 정한다.
4. 처리율 제한 장치에 걸리진 요청이라면 사용자에게 이 사실을 알려야 한다.

처리율 제한 장치 설계에 대한 요구사항을 정리하면 다음과 같다.
- 설정된 처리율을 초과하는 요청은 정확하게 제한한다.
- 낮은 응답 시간을 가져야 한다.
- 적은 메모리를 사용해야 한다.
- 하나의 처리율 제한 장치를 여러 서버에서 공유할 수 있어야 한다.
- 요청이 제한되었을 때는 그 사실을 사용자에게 알려야 한다.
- 처리율 제한 장치에 장애가 생기더라도 전체 시스템에 영햘을 주어서는 안되는 높은 결함 감내성을 가져야 한다.
## 2단계 개략적 설계안 제시 및 동의 구하기
#### 처리율 제한기를 어디에 둘 것인가?
처리율 제한기 장치는 크게 클라이언트 서버에 위치할 수 있다.
클라이언트에 위치한다면 요청을 쉽게 변조가 가능하기 때문에 API서버 또는 독립적인 서버에 처리율 제한 장치를 두는 것을 권장한다. 이 부분에 대해서는 정답이 없으며 회사의 현재 기술 스택이나 인력, 우선순위, 목표에 따라 달라질 수 있다.
#### 처리율 제한 알고리즘
###### 토큰 버킷 알고리즘
토큰 버킷은 지정된 용량을 갖는 컨테이너다. 이 버킷에는 사전에 설정된 양의 토큰이 토큰 공급기(refiller)에 의해 주기적으로 채워진다. 토큰이 꽉 찬 버킷에는 더 이상의 토큰이 추가되지 않고 버려진다(overflow).
❗️아마존과 스프라이트가 이 알고리즘을 사용하여 처리율 제한 장치를 설계함.   
https://www.youtube.com/watch?v=FU4WlwfS3G0

각 요청은 하나의 토큰을 사용하며 요청이 도착하면 버킷에 충분한 토큰이 있는지 검사한다. 충분한 토큰이 있는 경우 버킷에서 토큰을 하나 꺼낸 후 요청을 시스템에 전달하고 그렇지 않은 경우 해당 요청은 버려진다.

이 알고리즘에서 사용하는 인자는 다음과 같다.
- 버킷 크기: 버킷에 담을 수 있는 토큰의 최대 개수
- 토큰 공급률(refill rate): 초당 버킷에 채울 토큰의 개수

버킷을 몇 개 사용해야할 지는 공급 제한 규칙에 따라 달라진다. 아래는 대표적인 사례이다.
- API 엔드포인트마다 별토의 버킷을 둔다.
- IP 주서별로 버킷을 둔다.
- 모든 요청이 하나의 버킷을 공유하도록 한다.

이 알고리즘은 구현이 쉽고 메모리 사용 측면에서도 효율적이며 짧은 시간에 집중되는 트래픽도 처리가 가능하다. 하지만 버킷 크기와 토큰 공급률의 값을 적절하게 튜닝하는 것이 까다롭다.
###### 누출 버킷 알고리즘
누출 버킷 알고리즘은 처리율이 고정되어 있고 FIFO 큐로 구현한다. 동작원리는 다음과 같다.
1. 요청이 도착하면 큐가 가득 차 있는지 본다. 빈자리가 있는 경우에는 큐에 요청을 추가한다.
2. 큐가 가득 차 있는 경우에는 새 요청은 버린다.
3. 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.(처리율 고정)

❗️자바의 스레드 풀 동작 원리와 비슷 함. ThreadPoolExector를 생성할 때 workQueue에 크기를 고정하여 생성하게되면 3번을 제외한 위와 같은 방식으로 동작한다.

이 알고리즘에서 사용하는 인자는 다음과 같다.
- 버킷 크기:  큐 사이즈와 같은 값이다. 큐에는 처리될 항목들이 보관된다.
- 처리율(outflow rate): 지정된 시간당 몇 개의 항목을 처리할지 지정하는 값이다. 보통 초 단위로 표현된다.

이 알고리즘은 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적이며 고정된 처리율을 갖고 있기 때문에 안정적 출력(stable outflow rate)이 필요한 경우에 적합하다. 하지만 단시간에 많은 트래픽이 몰리는 경유 큐에는 오래된 요청이 쌓이게 되고, 그 요청들을 제때 처리 못하면 최신 요청들은 버려지게 된다. 또한 토큰 버킷 알고리즘과 같이 버킷 크기와 처리율의 값을 적적히 튜닝하기가 까다롭다.
#### 개략적인 아키텍처
처리율 제한 장치의 카운터는 빠른데다 시간에 기반한 만료 정책을 지원하는 메모리상에서 동작하는 캐시에 보관하는 게 바람직하다. 일례로 레디스는 처리율 제한 장치를 구현할 때 자주 사용되는 메모리 기반 저장장치다.

개략적인 아키텍처는 다음과 같다.
클라이언트 -> 처리율 제한 미들웨어 -> 레디스, API 서버
처리율 제한 미들웨어에는 레디스의 지정 버킷에서 카운터를 가져와 한도에 도달했는지 검사 후 API 서버로 요청을 전달할지 말지 결정한다. 한도에 도달하지 않았다면 카운터 값을 증가시키고 API 서버로 요청을 전달하고 도달했다면 요청은 거부된다.
## 3단계: 상세 설계
이 단계에서 설계할 부분은 다음과 같다.
- 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장되는가?
- 처리가 제한된 요청들은 어떻게 처리되는가?
- 분산 환경에서의 처리율 제한 장치의 구현
#### 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장되는가?
처리율 제한 규칙을 만들 때 고려해야 할 사항은 다음과 같습니다.
##### 1. 서비스의 특성
- **API의 중요도:** 중요한 API는 더 높은 처리율 제한을 설정하고, 덜 중요한 API는 낮은 제한을 설정한다.
- **사용자 수:** 전체 사용자 수와 예상되는 동시 접속자 수를 고려한다.
- **사용 패턴:** 특정 시간대에 요청이 집중되는지, 하루 동안 고르게 분포되는지를 파악한다.
##### 2. 사용자 유형
- **일반 사용자 vs. 프리미엄 사용자:** 프리미엄 사용자에게는 더 높은 처리율을 허용할 수 있다.
- **신뢰할 수 있는 사용자 vs. 신규 사용자:** 신규 사용자에게는 더 엄격한 제한을 적용하고, 시간이 지나면서 완화할 수 있다.
##### 3. 보안 고려사항
- **DDoS 방지:** 악의적인 트래픽을 차단할 수 있도록 IP 기반의 처리율 제한을 설정한다.
- **비정상적인 행동 탐지:** 비정상적으로 많은 요청을 보내는 사용자를 차단한다.
##### 4. 시스템 성능
- **서버 용량:** 서버의 처리 능력을 초과하지 않도록 제한을 설정한다.
- **데이터베이스 성능:** 데이터베이스 쿼리 수를 제한하여 성능 저하를 방지한다.
- **네트워크 대역폭:** 네트워크 대역폭 사용량을 고려하여 처리율을 설정한다.
##### 5. 규칙 적용의 유연성
- **동적 조정:** 트래픽 상황에 따라 실시간으로 제한을 조정할 수 있는 메커니즘을 마련한다.
- **API 별 차별화:** 모든 API에 동일한 제한을 적용하는 대신, 각 API에 맞춤형 제한을 적용한다.

위 고려사항을 토대로 만들어진 처리율 제한 규칙은 보통 설정파일 형태로 디스크에 저장된다. 별도의 작업 프로세스가 디스크에 있는 규칙을 읽어 캐시에 저장한다.
#### 처리가 제한된 요청들은 어떻게 처리되는가?
요청이 처리율 제한에 걸렸다면 요청을 버리고 too many request(status: 429)에러를 클라이언트에게 보내거나, 요청을 버리지 않고 메시지 큐에 보관했다가 추후에 처리할 수 있도록 처리할 수 있다.
#### 분산 환경에서의 처리율 제한 장치의 구현
여러 대의 서버와 병렬 스레드를 지원하는 시스템에서는 다음 두 가지 문제를 풀어야 한다.
- 경쟁 조건(race condition)
- 동기화(synchronization)
###### 경쟁 조건
처리율 제한 장치에서 특정 규칙의 카운터를 읽어와 임계치를 확인 후 기존 카운터 값을 1증가 시키는 경우 병렬 또는 동시성을 지원하는 환경에서는 경쟁 조건 이슈가 발생할 수 있다. 레디스를 사용한다면 sorted set 자료구를 사용하여 해결이 가능하다.
❗️레디스의 INCR 명령어도 원자적으로 수행되는데 책에서는 왜 sorted set을 언급했을까?
sorted set, icnr 둘 다 원자적으로 수행이 된다. 하지만 sorted set은 특정 범위의 요소를 조회하는 기능을 제공하기 때문에 언급된 거 같다.
https://www.youtube.com/watch?v=CRGPbCbRTHA
###### 동기화 이슈
여러 대의 처리율 제한 장치를 사용하는 환경에서는 처리율 제한 장치간의 데이터 동기화가 필요해진다. 이러한 문제를 해결하기 위해 레디스와 같은 중앙 집중형 데어티 저장소를 사용하여 데이터를 동기화하는 것이 바람직하다.

